#!/bin/bash
#
# webreport connects to the Results database and generates a web page as
# index.htm that includes links to all the results in the database. It
# generates images for the summary graphs, as well as for each test (the
# generic html files for each test are not regenerated, though - those come
# from benchwarmer, as does the pg_setting.txt file, and the test pgbench
# summary file)

source ./config
OUTFILE="results/index.htm"
RESULTPSQL="psql -h $RESULTHOST -U $RESULTUSER -p $RESULTPORT -d $RESULTDB"

# Emulate 'sed -i' behavior from GNU sed with standard sed instead.
# Needed on platforms like Solaris.
function sed-i {
  replace=$1
  filename=$2
  sed "$replace" ${filename} > ${filename}.new
  mv ${filename}.new ${filename}
}

# Produce combined report, averaged across all test sets
$RESULTPSQL -At -F" " -c "select scale,round(avg(dbsize) / (1024 * 1024)) as dbsize,round(avg(tps)) as tps from tests group by scale order by scale" > scaling.txt
gnuplot plots/scaling.plot 2>&1 | grep -v "Warning: empty"
mv scaling.svg results/
rm scaling.txt

$RESULTPSQL -At -F" " -c "select clients,round(avg(tps)) as tps from tests group by clients order by clients" > clients.txt
gnuplot plots/clients.plot 2>&1 | grep -v "Warning: empty"
mv clients.svg results/
rm clients.txt

# Copy the header HTML template to our outfile
if [ "$TABBED" -eq "1" ]; then
  cp templates/header-tabbed.html $OUTFILE
else
  cp templates/header.html $OUTFILE
fi

echo "<h3>Averages across all test sets:</h3>" >> $OUTFILE
echo "<img src=\"scaling.svg\"><p>" >> $OUTFILE
echo "<img src=\"clients.svg\"><p>" >> $OUTFILE
echo "<h3>Test sets comparison:</h3>" >> $OUTFILE
echo "<img src=\"scaling-sets.svg\"><p>" >> $OUTFILE
echo "<img src=\"clients-sets.svg\"><p>" >> $OUTFILE

# Loop over all the active test sets
SETS=`$RESULTPSQL -A -t -c "select set from tests group by set order by set"`
TESTS=`$RESULTPSQL -A -t -c "select test from tests order by test"`

# Build table of contents
echo '<ul>' >> $OUTFILE
for SET in $SETS ; do
  DESCR=`$RESULTPSQL -A -t -c "select info from testset where set='$SET'"`
  echo "<li><a href='#set-$SET'>$DESCR</a></li>" >> $OUTFILE
done
echo '</ul>' >> $OUTFILE

for SET in $SETS ; do
  DESCR=`$RESULTPSQL -A -t -c "select info from testset where set='$SET'"`
  STARTED=`$RESULTPSQL -A -t -c "select to_char(min(start_time), 'YYYY-MM-DD HH24:MI:SS') from tests where set='$SET'"`
  FINISHED=`$RESULTPSQL -A -t -c "select to_char(max(end_time), 'YYYY-MM-DD HH24:MI:SS') from tests where set='$SET'"`
  echo "<div id='set-$SET'>" >> $OUTFILE
  echo "<hr><h3>Set" $SET : $DESCR"</h3>" >> $OUTFILE

  # We'll need to know the last set plot for the multi-plot below
  LASTSET="$SET"

  # Generate graphs for just this test set
  $RESULTPSQL -At -F" " -c "select scale,round(avg(dbsize) / (1024 * 1024)) as dbsize,round(avg(tps)) as tps from tests where set='$SET' group by scale order by scale" > scaling.txt
  gnuplot plots/scaling.plot 2>&1 | grep -v "Warning: empty"
  mv scaling.svg results/scaling-$SET.svg
  mv scaling.txt scaling-$SET.txt

  $RESULTPSQL -At -F" " -c "select clients,round(avg(tps)) as tps from tests where set='$SET' group by clients order by clients" > clients.txt
  gnuplot plots/clients.plot 2>&1 | grep -v "Warning: empty"
  mv clients.svg results/clients-$SET.svg
  mv clients.txt clients-$SET.txt

  # Summarize the test set
  echo Averages for test set $SET by scale: >> $OUTFILE
  $RESULTPSQL -H -X >> $OUTFILE <<ff
  select set,
	 scale,
	 to_char(round(avg(tps)), 'FM9G999G999G999G999') as avg_tps,
	 round(1000 * avg(avg_latency)) / 1000 as avg_avg_latency,
	 round(1000 * avg(percentile_90_latency)) / 1000 as "avg 90%<",
	 round(1000 * max(max_latency)) / 1000 as max_latency
	 from tests where tests.set='$SET'
	 group by set, scale
	 order by set, scale;
ff

  echo Averages for test set $SET by clients: >> $OUTFILE
  $RESULTPSQL -H -X >> $OUTFILE <<ff
  select set,
	  clients,
	  to_char(round(avg(tps)), 'FM9G999G999G999G999') as avg_tps,
	  round(1000 * avg(avg_latency)) / 1000 as avg_avg_latency,
	  round(1000 * avg(percentile_90_latency)) / 1000 as "avg 90%<",
	  round(1000 * max(max_latency)) / 1000 as max_latency
	  from tests where tests.set='$SET'
	  group by set, clients
	  order by set, clients;
ff

  echo Averages for test set $SET by scale, client, and rate limit: >> $OUTFILE
  $RESULTPSQL -H -X >> $OUTFILE <<ff
  select set,
	  scale,
	  clients,
	  coalesce(rate_limit::text, '(none)') as rate_limit,
	  to_char(round(avg(tps)), 'FM9G999G999G999G999') as avg_tps,
	  to_char(round(stddev(tps)), 'FM9G999G999G999G999') as tps_stddev,
	  round(1000 * avg(avg_latency)) / 1000 as avg_avg_latency,
	  round(1000 * avg(percentile_90_latency)) / 1000 as "avg 90%<",
	  round(1000 * max(max_latency)) / 1000 as max_latency
        from tests where tests.set='$SET'
	group by set, scale, clients, rate_limit
	order by set, scale, clients, rate_limit;
ff

  echo Detail for test set $SET: >> $OUTFILE
  # Create a line showing the results for every test as an HTML table
  $RESULTPSQL -H -X > temp.txt <<ff
  select set,'<a href="' || tests.test || '/index.html">' || tests.test || '</a>' as test,
	scale,
	clients,
	coalesce(rate_limit::text, '(none)') as rate_limit,
	to_char(round(tps), 'FM9G999G999G999G999') as tps,
	round(1000 * avg_latency) / 1000 as avg_latency,
	max_latency,
	to_char(checkpoints_timed + checkpoints_req, 'FM9G999G999G999G999') as chkpts,
	to_char(buffers_checkpoint , 'FM9G999G999G999G999') as buf_check,
	to_char(buffers_clean , 'FM9G999G999G999G999') as buf_clean,
	to_char(buffers_backend, 'FM9G999G999G999G999') as buf_backend,
	to_char(buffers_alloc, 'FM9G999G999G999G999') as buf_alloc,
	to_char(maxwritten_clean, 'FM9G999G999G999G999') as max_clean,
	to_char(max_dirty, 'FM9G999G999G999G999') as max_dirty,
	to_char(wal_written, 'FM9G999G999G999G999') as wal_written,
	to_char(start_time, 'HH24:MI:SS') as start,
	cleanup
	from test_bgwriter right join tests on tests.test = test_bgwriter.test
	where tests.set='$SET'
	order by set, scale, clients, rate_limit, tests.test;
ff

  # Now we need to fix lines like this
  # <td align="left">&lt;a href=&quot;results/201/&quot;&gt;201&lt;/a&gt;</td>
  # where PSQL has quoted things we wanted literally
  sed-i "s/&lt;/</g" temp.txt
  sed-i "s/&gt;/>/g" temp.txt
  sed-i "s/&quot;/\"/g" temp.txt
  cat temp.txt >> $OUTFILE
  echo "<hr><h6>($DESCR started $STARTED, finished $FINISHED)</h6></hr>" >> $OUTFILE
  echo "<img src=\"scaling-$SET.svg\"><p>" >> $OUTFILE
  echo "<img src=\"clients-$SET.svg\"><p>" >> $OUTFILE

  # Remove row counts
  cp $OUTFILE temp.txt
  cat temp.txt | grep -v " rows*)" > $OUTFILE
  echo "</div>" >> $OUTFILE
done

# Plot set comparison
cat > multi-client.plot << "ENDING"
set terminal svg size 800,600
set output "clients-sets.svg"
set title "pgbench transactions/sec"
set mytics
set grid xtics ytics mytics
set xlabel "Clients"
set ylabel "TPS"
plot \
ENDING

cat > multi-scale.plot << "ENDING"
set terminal svg size 800,600
set output "scaling-sets.svg"
set title "pgbench transactions/sec"
set mytics
set grid xtics ytics mytics
set xlabel "Scaling factor"
set ylabel "TPS"
plot \
ENDING

for SET in $SETS ; do
  # Trimmed down descriptions needed to fit into the graph key
  DESCR=`$RESULTPSQL -A -t -c "select substring(info from 1 for 35) from testset where set='$SET'"`

  if [ "$SET" -eq "$LASTSET" ] ; then
    DELIM=""
  else
    DELIM=",\\"
  fi

  echo  "'scaling-$SET.txt' using 1:3 axis x1y1 title '$DESCR' with linespoints $DELIM" >> multi-scale.plot
  echo  "'clients-$SET.txt' using 1:2 axis x1y1 title '$DESCR' with linespoints $DELIM" >> multi-client.plot

done

gnuplot multi-scale.plot 2>&1 | grep -v "Warning: empty"
gnuplot multi-client.plot 2>&1 | grep -v "Warning: empty"
mv clients-sets.svg results/
mv scaling-sets.svg results/
rm multi-scale.plot
rm multi-client.plot

for SET in $SETS ; do
  rm scaling-$SET.txt clients-$SET.txt
done

rm temp.txt
cat templates/footer.html >> $OUTFILE

for TEST in $TESTS ; do
  # Re-create CSV file for each test, to generate individual test graphs

  $RESULTPSQL -A -t -F' ' -c "select extract(epoch from date_trunc('second', ts)), count(*) from timing where test = '$TEST' group by date_trunc('second', ts) order by date_trunc('second', ts)" > tpsdata.txt
  gnuplot $BASEDIR/plots/tps.script

  $RESULTPSQL -A -t -F' ' -c "select extract(epoch from ts), latency from timing where test = '$TEST'" > latency.txt
  gnuplot $BASEDIR/plots/latency.script

  $RESULTPSQL -t -A -F"," -c "select extract (epoch from taken), cpu_perc_usr, cpu_perc_sys, cpu_perc_idle, cpu_perc_wait, cpu_perc_hiq, cpu_perc_siq, mem_used_bytes, mem_buff_bytes, mem_cache_bytes, mem_free_bytes, swap_pages_used, swap_pages_free, paging_pages_in, paging_pages_out, system_interrupts, system_context_switches, disk_read_ops, disk_write_ops from test_dstat where test = '$TEST' order by dstatid asc" > $BASEDIR/dstat.stat

  gnuplot $BASEDIR/plots/memory.script
  gnuplot $BASEDIR/plots/disk.script
  gnuplot $BASEDIR/plots/cpu.script
  gnuplot $BASEDIR/plots/paging.script
  gnuplot $BASEDIR/plots/swap.script
  gnuplot $BASEDIR/plots/system.script

  mv $BASEDIR/tps.svg $BASEDIR/results/$TEST
  mv $BASEDIR/latency.png $BASEDIR/results/$TEST
  mv $BASEDIR/memory.svg $BASEDIR/results/$TEST
  mv $BASEDIR/disk.svg $BASEDIR/results/$TEST
  mv $BASEDIR/cpu.svg $BASEDIR/results/$TEST
  mv $BASEDIR/paging.svg $BASEDIR/results/$TEST
  mv $BASEDIR/swap.svg $BASEDIR/results/$TEST
  mv $BASEDIR/system.svg $BASEDIR/results/$TEST

  rm tpsdata.txt
  rm latency.txt
done

# Delete last remaining CSV temp stat file
rm $BASEDIR/dstat.stat
